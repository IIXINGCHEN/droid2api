/**
 * Token æå–å·¥å…·
 * BaSui: ä¸“é—¨ç”¨æ¥ä» Anthropic/OpenAI å“åº”ä¸­æå–å®Œæ•´çš„ Token ç»Ÿè®¡
 * æ”¯æŒï¼šinput_tokens, output_tokens, thinking_tokens, cache_creation_tokens, cache_read_tokens
 */

import { logDebug } from '../logger.js';

/**
 * ä» Anthropic æµå¼å“åº”ä¸­æå–å®Œæ•´ Token ç»Ÿè®¡
 * @param {Object} data - SSE äº‹ä»¶æ•°æ®
 * @param {Object} tokenStats - Token ç»Ÿè®¡å¯¹è±¡ï¼ˆä¼šè¢«ä¿®æ”¹ï¼‰
 * @returns {void}
 */
export function extractAnthropicTokens(data, tokenStats) {
  try {
    // message_start äº‹ä»¶ï¼šåŒ…å«è¾“å…¥ Token å’Œç¼“å­˜ç»Ÿè®¡
    if (data.type === 'message_start' && data.message?.usage) {
      const usage = data.message.usage;
      tokenStats.inputTokens = usage.input_tokens || 0;
      tokenStats.cacheCreationTokens = usage.cache_creation_input_tokens || 0;
      tokenStats.cacheReadTokens = usage.cache_read_input_tokens || 0;

      logDebug(`âœ… Anthropic message_start: input=${tokenStats.inputTokens}, cache_creation=${tokenStats.cacheCreationTokens}, cache_read=${tokenStats.cacheReadTokens}`);
    }

    // message_delta äº‹ä»¶ï¼šåŒ…å«è¾“å‡º Tokenï¼ˆç´¯è®¡å€¼ï¼‰å’Œæ¨ç† Token
    if (data.type === 'message_delta' && data.usage) {
      const usage = data.usage;
      // BaSui: output_tokens æ˜¯ç´¯è®¡å€¼ï¼Œä¸æ˜¯å¢é‡ï¼ç›´æ¥èµ‹å€¼ï¼Œä¸è¦ç”¨ +=
      tokenStats.outputTokens = usage.output_tokens || 0;

      // BaSui: ğŸ”¥ é‡è¦ï¼Extended Thinking çš„ Token ç»Ÿè®¡ï¼ˆè¿™ä¸ªä¹‹å‰æ¼äº†ï¼ï¼‰
      if (usage.thinking_output_tokens !== undefined) {
        tokenStats.thinkingTokens = usage.thinking_output_tokens || 0;
        logDebug(`ğŸ’¡ Thinking tokens detected: ${tokenStats.thinkingTokens}`);
      }

      logDebug(`âœ… Anthropic message_delta: output=${tokenStats.outputTokens}, thinking=${tokenStats.thinkingTokens}`);
    }
  } catch (error) {
    logDebug('âš ï¸ Error extracting Anthropic tokens', error);
  }
}

/**
 * ä» OpenAI æµå¼å“åº”ä¸­æå–å®Œæ•´ Token ç»Ÿè®¡
 * @param {Object} data - SSE äº‹ä»¶æ•°æ®
 * @param {Object} tokenStats - Token ç»Ÿè®¡å¯¹è±¡ï¼ˆä¼šè¢«ä¿®æ”¹ï¼‰
 * @returns {void}
 */
export function extractOpenAITokens(data, tokenStats) {
  try {
    if (data.usage) {
      tokenStats.inputTokens = data.usage.prompt_tokens || data.usage.input_tokens || 0;
      tokenStats.outputTokens = data.usage.completion_tokens || data.usage.output_tokens || 0;

      logDebug(`âœ… OpenAI tokens: input=${tokenStats.inputTokens}, output=${tokenStats.outputTokens}`);
    }
  } catch (error) {
    logDebug('âš ï¸ Error extracting OpenAI tokens', error);
  }
}

/**
 * ä» Commonï¼ˆé€šç”¨ï¼‰æµå¼å“åº”ä¸­æå– Token ç»Ÿè®¡
 * @param {Object} data - SSE äº‹ä»¶æ•°æ®
 * @param {Object} tokenStats - Token ç»Ÿè®¡å¯¹è±¡ï¼ˆä¼šè¢«ä¿®æ”¹ï¼‰
 * @returns {void}
 */
export function extractCommonTokens(data, tokenStats) {
  try {
    if (data.usage) {
      tokenStats.inputTokens = data.usage.prompt_tokens || data.usage.input_tokens || 0;
      tokenStats.outputTokens = data.usage.completion_tokens || data.usage.output_tokens || 0;

      logDebug(`âœ… Common tokens: input=${tokenStats.inputTokens}, output=${tokenStats.outputTokens}`);
    }
  } catch (error) {
    logDebug('âš ï¸ Error extracting Common tokens', error);
  }
}

/**
 * åˆ›å»ºç©ºçš„ Token ç»Ÿè®¡å¯¹è±¡
 * @returns {Object}
 */
export function createTokenStats() {
  return {
    inputTokens: 0,
    outputTokens: 0,
    thinkingTokens: 0,
    cacheCreationTokens: 0,
    cacheReadTokens: 0
  };
}

/**
 * è®¡ç®—æ€» Token æ•°
 * @param {Object} tokenStats
 * @returns {number}
 */
export function getTotalTokens(tokenStats) {
  return (
    (tokenStats.inputTokens || 0) +
    (tokenStats.outputTokens || 0) +
    (tokenStats.thinkingTokens || 0)
    // BaSui: ç¼“å­˜ Token ä¸è®¡å…¥æ€»æ•°ï¼ˆFactory API ä¹Ÿä¸è®¡è´¹ï¼‰
  );
}

export default {
  extractAnthropicTokens,
  extractOpenAITokens,
  extractCommonTokens,
  createTokenStats,
  getTotalTokens
};
