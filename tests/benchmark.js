/**
 * ğŸš€ droid2api æ€§èƒ½å‹æµ‹è„šæœ¬
 *
 * ä½¿ç”¨æ–¹å¼ï¼š
 * node tests/benchmark.js
 *
 * åŠŸèƒ½ï¼š
 * - æµ‹è¯• /v1/models æ¥å£ååé‡
 * - æµ‹è¯• /v1/chat/completions æ¥å£å»¶è¿Ÿ
 * - ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
 */

import fetch from 'node-fetch';
import { performance } from 'perf_hooks';

// é…ç½®
const CONFIG = {
  baseUrl: 'http://localhost:3000',
  apiKey: process.env.API_ACCESS_KEY || 'your-api-key',
  tests: {
    models: {
      name: 'GET /v1/models',
      concurrent: 100,
      total: 1000
    },
    chatCompletions: {
      name: 'POST /v1/chat/completions',
      concurrent: 50,
      total: 200
    }
  }
};

// æ€§èƒ½ç»Ÿè®¡å™¨
class PerformanceStats {
  constructor(name) {
    this.name = name;
    this.latencies = [];
    this.errors = 0;
    this.startTime = 0;
    this.endTime = 0;
  }

  start() {
    this.startTime = performance.now();
  }

  addRequest(latency, isError = false) {
    this.latencies.push(latency);
    if (isError) this.errors++;
  }

  finish() {
    this.endTime = performance.now();
  }

  getReport() {
    if (this.latencies.length === 0) {
      return { error: 'No requests completed' };
    }

    const sorted = [...this.latencies].sort((a, b) => a - b);
    const total = this.latencies.length;
    const totalTime = (this.endTime - this.startTime) / 1000; // ç§’

    return {
      name: this.name,
      total: total,
      errors: this.errors,
      errorRate: ((this.errors / total) * 100).toFixed(2) + '%',
      duration: totalTime.toFixed(2) + 's',
      rps: (total / totalTime).toFixed(2),
      latency: {
        min: sorted[0].toFixed(2) + 'ms',
        max: sorted[sorted.length - 1].toFixed(2) + 'ms',
        avg: (sorted.reduce((a, b) => a + b, 0) / total).toFixed(2) + 'ms',
        p50: sorted[Math.floor(total * 0.5)].toFixed(2) + 'ms',
        p90: sorted[Math.floor(total * 0.9)].toFixed(2) + 'ms',
        p99: sorted[Math.floor(total * 0.99)].toFixed(2) + 'ms'
      }
    };
  }

  printReport() {
    const report = this.getReport();
    if (report.error) {
      console.error(`âŒ ${this.name}: ${report.error}`);
      return;
    }

    console.log(`\n${'='.repeat(80)}`);
    console.log(`ğŸ“Š ${report.name} - æ€§èƒ½æŠ¥å‘Š`);
    console.log(`${'='.repeat(80)}`);
    console.log(`æ€»è¯·æ±‚æ•°:    ${report.total}`);
    console.log(`é”™è¯¯æ•°:      ${report.errors} (${report.errorRate})`);
    console.log(`æµ‹è¯•æ—¶é•¿:    ${report.duration}`);
    console.log(`ååé‡:      ${report.rps} req/s`);
    console.log(`\nå»¶è¿Ÿç»Ÿè®¡:`);
    console.log(`  æœ€å°å€¼:    ${report.latency.min}`);
    console.log(`  å¹³å‡å€¼:    ${report.latency.avg}`);
    console.log(`  P50:       ${report.latency.p50}`);
    console.log(`  P90:       ${report.latency.p90}`);
    console.log(`  P99:       ${report.latency.p99}`);
    console.log(`  æœ€å¤§å€¼:    ${report.latency.max}`);
    console.log(`${'='.repeat(80)}\n`);
  }
}

// æµ‹è¯• /v1/models æ¥å£
async function testModels() {
  const config = CONFIG.tests.models;
  const stats = new PerformanceStats(config.name);

  console.log(`\nğŸš€ å¼€å§‹æµ‹è¯•: ${config.name}`);
  console.log(`   å¹¶å‘æ•°: ${config.concurrent}, æ€»è¯·æ±‚: ${config.total}\n`);

  stats.start();

  // å¹¶å‘æ§åˆ¶
  let completed = 0;
  const queue = [];

  async function makeRequest() {
    const startTime = performance.now();
    try {
      const response = await fetch(`${CONFIG.baseUrl}/v1/models`, {
        headers: {
          'x-api-key': CONFIG.apiKey
        }
      });

      const latency = performance.now() - startTime;

      if (response.ok) {
        stats.addRequest(latency, false);
        process.stdout.write(`\râœ“ å®Œæˆ: ${++completed}/${config.total}`);
      } else {
        stats.addRequest(latency, true);
        process.stdout.write(`\râŒ å¤±è´¥: ${++completed}/${config.total} (HTTP ${response.status})`);
      }
    } catch (error) {
      const latency = performance.now() - startTime;
      stats.addRequest(latency, true);
      process.stdout.write(`\râŒ å¤±è´¥: ${++completed}/${config.total} (${error.message})`);
    }
  }

  // åˆ†æ‰¹å‘é€è¯·æ±‚
  for (let i = 0; i < config.total; i++) {
    if (queue.length >= config.concurrent) {
      await Promise.race(queue);
    }
    const promise = makeRequest();
    queue.push(promise);
    promise.then(() => {
      const index = queue.indexOf(promise);
      if (index > -1) queue.splice(index, 1);
    });
  }

  // ç­‰å¾…æ‰€æœ‰è¯·æ±‚å®Œæˆ
  await Promise.all(queue);
  console.log(); // æ¢è¡Œ

  stats.finish();
  stats.printReport();

  return stats.getReport();
}

// æµ‹è¯• /v1/chat/completions æ¥å£
async function testChatCompletions() {
  const config = CONFIG.tests.chatCompletions;
  const stats = new PerformanceStats(config.name);

  console.log(`\nğŸš€ å¼€å§‹æµ‹è¯•: ${config.name}`);
  console.log(`   å¹¶å‘æ•°: ${config.concurrent}, æ€»è¯·æ±‚: ${config.total}\n`);

  stats.start();

  let completed = 0;
  const queue = [];

  async function makeRequest() {
    const startTime = performance.now();
    try {
      const response = await fetch(`${CONFIG.baseUrl}/v1/chat/completions`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'x-api-key': CONFIG.apiKey
        },
        body: JSON.stringify({
          model: 'claude-sonnet-4-5-20250929',
          messages: [
            { role: 'user', content: 'Hello' }
          ],
          max_tokens: 10,
          stream: false
        })
      });

      const latency = performance.now() - startTime;

      if (response.ok) {
        stats.addRequest(latency, false);
        process.stdout.write(`\râœ“ å®Œæˆ: ${++completed}/${config.total}`);
      } else {
        stats.addRequest(latency, true);
        process.stdout.write(`\râŒ å¤±è´¥: ${++completed}/${config.total} (HTTP ${response.status})`);
      }
    } catch (error) {
      const latency = performance.now() - startTime;
      stats.addRequest(latency, true);
      process.stdout.write(`\râŒ å¤±è´¥: ${++completed}/${config.total} (${error.message})`);
    }
  }

  for (let i = 0; i < config.total; i++) {
    if (queue.length >= config.concurrent) {
      await Promise.race(queue);
    }
    const promise = makeRequest();
    queue.push(promise);
    promise.then(() => {
      const index = queue.indexOf(promise);
      if (index > -1) queue.splice(index, 1);
    });
  }

  await Promise.all(queue);
  console.log(); // æ¢è¡Œ

  stats.finish();
  stats.printReport();

  return stats.getReport();
}

// ä¸»å‡½æ•°
async function main() {
  console.log(`
${'='.repeat(80)}
ğŸš€ droid2api æ€§èƒ½å‹æµ‹å·¥å…·
${'='.repeat(80)}
ç›®æ ‡æœåŠ¡å™¨: ${CONFIG.baseUrl}
APIå¯†é’¥:    ${CONFIG.apiKey.substring(0, 10)}...
${'='.repeat(80)}
`);

  // æ£€æŸ¥æœåŠ¡å™¨æ˜¯å¦å¯ç”¨
  console.log('ğŸ” æ£€æŸ¥æœåŠ¡å™¨è¿æ¥...');
  try {
    const response = await fetch(`${CONFIG.baseUrl}/`, {
      headers: { 'x-api-key': CONFIG.apiKey }
    });
    if (response.ok) {
      console.log('âœ… æœåŠ¡å™¨è¿æ¥æ­£å¸¸\n');
    } else {
      console.error(`âŒ æœåŠ¡å™¨è¿”å›é”™è¯¯: HTTP ${response.status}`);
      process.exit(1);
    }
  } catch (error) {
    console.error(`âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨: ${error.message}`);
    process.exit(1);
  }

  // è¿è¡Œæµ‹è¯•
  const results = {
    models: await testModels(),
    chatCompletions: await testChatCompletions()
  };

  // æ‰“å°æ€»ç»“
  console.log(`
${'='.repeat(80)}
ğŸ“ˆ å‹æµ‹æ€»ç»“
${'='.repeat(80)}
/v1/models:
  ååé‡: ${results.models.rps} req/s
  å¹³å‡å»¶è¿Ÿ: ${results.models.latency.avg}
  é”™è¯¯ç‡: ${results.models.errorRate}

/v1/chat/completions:
  ååé‡: ${results.chatCompletions.rps} req/s
  å¹³å‡å»¶è¿Ÿ: ${results.chatCompletions.latency.avg}
  é”™è¯¯ç‡: ${results.chatCompletions.errorRate}
${'='.repeat(80)}

ğŸ’¡ æç¤º:
  - å¦‚æœååé‡ < 500 req/sï¼Œè€ƒè™‘å¯ç”¨è¿æ¥æ± ä¼˜åŒ–
  - å¦‚æœå¹³å‡å»¶è¿Ÿ > 200msï¼Œæ£€æŸ¥ä¸Šæ¸¸ API å“åº”é€Ÿåº¦
  - å¦‚æœé”™è¯¯ç‡ > 5%ï¼Œæ£€æŸ¥å¯†é’¥æ± é…ç½®å’Œä¸Šæ¸¸é™æµ
${'='.repeat(80)}
`);
}

// è¿è¡Œ
main().catch(error => {
  console.error('âŒ å‹æµ‹å¤±è´¥:', error);
  process.exit(1);
});
